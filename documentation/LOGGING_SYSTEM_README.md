# ğŸ“‹ ××¢×¨×›×ª ×œ×•×’×™× ×›×œ×œ×™×ª - RedshiftManager

## ğŸ¯ ×¡×§×™×¨×” ×›×œ×œ×™×ª

××¢×¨×›×ª ×œ×•×’×™× ××ª×§×“××ª ×•××§×™×¤×” ×¢×‘×•×¨ RedshiftManager ×”×›×•×œ×œ×ª:
- **Structured Logging** ×¢× JSON format
- **×©××™×¨×” ×‘×‘×¡×™×¡ × ×ª×•× ×™×** SQLite ×¢× indexing
- **×××©×§ ×¦×¤×™×™×” ××™× ×˜×¨××§×˜×™×‘×™** ×¢× ×¡×™× ×•×Ÿ ×•×—×™×¤×•×©
- **×× ×œ×™×˜×™×§×¡ ××ª×§×“×** ×œ×–×™×”×•×™ ×“×¤×•×¡×™× ×•×ª×•×‘× ×•×ª
- **×™×™×¦×•× ×•×’×™×‘×•×™** ×‘××¡×¤×¨ ×¤×•×¨××˜×™×
- **×”×ª×¨××•×ª** ×œ×©×’×™××•×ª ×§×¨×™×˜×™×•×ª (Slack)

---

## ğŸ—ï¸ ××¨×›×™×˜×§×˜×•×¨×”

### ×§×‘×¦×™ ×”××¢×¨×›×ª

```
core/
â”œâ”€â”€ logging_system.py    # ××¢×¨×›×ª ×”×œ×•×’×™× ×”××¨×›×–×™×ª
â”œâ”€â”€ log_analytics.py     # ××•×“×•×œ ×× ×œ×™×˜×™×§×¡ ××ª×§×“×
â””â”€â”€ log_export.py        # ××•×“×•×œ ×™×™×¦×•× ×•×’×™×‘×•×™

pages/
â””â”€â”€ logs_viewer.py       # ×××©×§ ×”×¦×¤×™×™×” ×‘×œ×•×’×™×

logs/                    # ×ª×™×§×™×™×ª ×”×œ×•×’×™×
â”œâ”€â”€ logs.db             # ×‘×¡×™×¡ × ×ª×•× ×™× SQLite
â”œâ”€â”€ redshift_manager.log # ×œ×•×’ ×˜×§×¡×˜ ×¨×’×™×œ
â”œâ”€â”€ redshift_manager.json # ×œ×•×’ JSON ××•×‘× ×”
â””â”€â”€ errors.log          # ×œ×•×’ ×©×’×™××•×ª ×‘×œ×‘×“

exports/                 # ×ª×™×§×™×™×ª ×™×™×¦×•××™× ×•×’×™×‘×•×™×™×
â”œâ”€â”€ logs_export_*.csv
â”œâ”€â”€ logs_export_*.json
â””â”€â”€ logs_backup_*.zip
```

### ×¨×›×™×‘×™ ×”××¢×¨×›×ª

1. **RedshiftManagerLogger** - ××—×œ×§×” ××¨×›×–×™×ª ×œ× ×™×”×•×œ ×”×œ×•×’×™×
2. **JSONFormatter** - ×¤×•×¨××˜×¨ ×œ-JSON ××•×‘× ×”
3. **DatabaseHandler** - handler ×œ×©××™×¨×” ×‘×‘×¡×™×¡ × ×ª×•× ×™×
4. **SlackHandler** - handler ×œ×”×ª×¨××•×ª Slack
5. **LogAnalytics** - ××•×“×•×œ ×× ×œ×™×˜×™×§×¡ ××ª×§×“×
6. **LogExporter** - ××•×“×•×œ ×™×™×¦×•× ×•×’×™×‘×•×™

---

## ğŸš€ ×”×ª×—×œ×” ××”×™×¨×”

### ×”×¤×¢×œ×ª ×”××¢×¨×›×ª

```python
from core.logging_system import get_logger, log_user_action, log_operation

# ×§×‘×œ×ª logger
logger = get_logger("my_module")

# ×œ×•×’×™× ×‘×¡×™×¡×™×™×
logger.info("Application started")
logger.error("Database connection failed")

# ×œ×•×’×™× ×¢× context
log_user_action("login", user_id="admin", session_id="sess123")
log_operation("QUERY_EXECUTION", user_id="analyst", duration=1500)
```

### ×™×¦×™×¨×ª ×œ×•×’×™× ×œ×“×•×’××”

```bash
python test_logging_system.py
```

### ×¦×¤×™×™×” ×‘×œ×•×’×™×

1. **×“×¨×š ×”××¢×¨×›×ª ×”×¨××©×™×ª**: ×¢××•×“ "ğŸ“‹ Logs Viewer"
2. **×”×¨×¦×” ×™×©×™×¨×”**: `streamlit run pages/logs_viewer.py`

---

## ğŸ“Š ×¡×•×’×™ ×œ×•×’×™×

### 1. ×œ×•×’×™× ×›×œ×œ×™×™×
```python
logger = get_logger("module_name")
logger.debug("Debug information")
logger.info("General information")
logger.warning("Warning message")
logger.error("Error occurred")
logger.critical("Critical system error")
```

### 2. ×œ×•×’×™ ×¤×¢×•×œ×•×ª
```python
log_operation(
    operation="CLUSTER_CONNECT",
    level="INFO",
    user_id="admin",
    cluster_id="prod-cluster",
    duration=2500,  # milliseconds
    status="SUCCESS"
)
```

### 3. ×œ×•×’×™ ×©××™×œ×ª×•×ª
```python
log_query(
    query="SELECT * FROM users",
    cluster_id="prod-cluster", 
    user_id="analyst",
    duration=1200,
    rows_affected=150,
    status="SUCCESS"
)
```

### 4. ×œ×•×’×™ ×¤×¢×•×œ×•×ª ××©×ª××©
```python
log_user_action(
    action="page_view",
    user_id="user123",
    session_id="sess456",
    page="dashboard",
    ip_address="192.168.1.100"
)
```

### 5. ×œ×•×’×™ ××™×¨×•×¢×™ ××¢×¨×›×ª
```python
log_system_event(
    event="BACKUP_COMPLETED",
    severity="INFO",
    cluster_id="prod-cluster",
    backup_size="2.5GB"
)
```

---

## ğŸ” ×××©×§ ×”×¦×¤×™×™×”

### ×ª×›×•× ×•×ª ×¢×™×§×¨×™×•×ª

#### ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª
- ×¡×š ×›×œ ×”×œ×•×’×™× ×‘××¢×¨×›×ª
- ×œ×•×’×™× ×‘-24 ×©×¢×•×ª ××—×¨×•× ×•×ª
- ×©×’×™××•×ª ×‘×©×‘×•×¢ ×”××—×¨×•×Ÿ
- ××—×•×– ×©×’×™××•×ª
- ×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×¨××•×ª ×•××•×“×•×œ×™×

#### ğŸ” ×—×™×¤×•×© ×•×¡×™× ×•×Ÿ
- **×˜×•×•×— ×ª××¨×™×›×™×**: ×‘×—×™×¨×ª ×ª×§×•×¤×” ×œ× ×™×ª×•×—
- **×¨××ª ×œ×•×’**: ×¡×™× ×•×Ÿ ×œ×¤×™ DEBUG, INFO, WARNING, ERROR, CRITICAL
- **××•×“×•×œ**: ×¡×™× ×•×Ÿ ×œ×¤×™ ××•×“×•×œ ×¡×¤×¦×™×¤×™
- **×—×™×¤×•×© ×˜×§×¡×˜**: ×—×™×¤×•×© ×—×•×¤×©×™ ×‘×ª×•×›×Ÿ ×”×”×•×“×¢×•×ª
- **××’×‘×œ×ª ×ª×•×¦××•×ª**: ×”×’×“×¨×ª ××¡×¤×¨ ××§×¡×™××œ×™ ×©×œ ×ª×•×¦××•×ª

#### ğŸ“ˆ Timeline
- ×’×¨×£ ×–××Ÿ ×©×œ × ×¤×— ×œ×•×’×™×
- ×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×¨××•×ª ×œ××•×¨×š ×–××Ÿ
- ×–×™×”×•×™ ×©×¢×•×ª ×©×™×

#### ğŸ“‹ ×˜×‘×œ×ª ×ª×•×¦××•×ª
- ×”×¦×’×” ×˜×‘×œ××™×ª ×©×œ ×”×œ×•×’×™×
- ×‘×—×™×¨×ª ×¢××•×“×•×ª ×œ×”×¦×’×”
- ×¤×¨×˜×™× ××œ××™× ×©×œ ×œ×•×’ × ×‘×—×¨
- Exception details ×•-stack traces

#### ğŸ’¾ ×™×™×¦×•×
- ×™×™×¦×•× ×œ-CSV, JSON, Excel
- ×“×—×™×¡×” ××•×˜×•××˜×™×ª ×©×œ ×§×‘×¦×™× ×’×“×•×œ×™×

---

## ğŸ“ˆ ××¢×¨×›×ª ×× ×œ×™×˜×™×§×¡

### × ×™×ª×•×— ×“×¤×•×¡×™ ×©×’×™××•×ª

```python
from core.log_analytics import LogAnalytics

analytics = LogAnalytics()
error_analysis = analytics.analyze_error_patterns(days=7)

print(f"×¡×š ×©×’×™××•×ª: {error_analysis['total_errors']}")
print(f"×©×’×™××•×ª ×™×™×—×•×“×™×•×ª: {error_analysis['unique_errors']}")
```

#### ×ª×›×•× ×•×ª ×”×× ×œ×™×˜×™×§×¡

1. **×§×˜×’×•×¨×™×–×¦×™×” ××•×˜×•××˜×™×ª** ×©×œ ×©×’×™××•×ª ×œ×¤×™ ×¡×•×’
2. **×–×™×”×•×™ ×“×¤×•×¡×™× ×—×•×–×¨×™×** ×•×©×’×™××•×ª ×‘×¨×¦×£
3. **× ×™×ª×•×— ×¤×¨×¦×™ ×©×’×™××•×ª** (error bursts)
4. **××’××•×ª ×œ××•×¨×š ×–××Ÿ** ×¢× ×—×™×©×•×‘ ×˜×¨× ×“×™×

### × ×™×ª×•×— ×‘×™×¦×•×¢×™×

```python
performance_analysis = analytics.analyze_performance_trends(days=7)

print(f"×–××Ÿ ×××•×¦×¢: {performance_analysis['avg_duration']:.2f}ms")
print(f"P95: {performance_analysis['p95_duration']:.2f}ms")
```

#### ××“×“×™ ×‘×™×¦×•×¢×™×

1. **×–×× ×™ ×‘×™×¦×•×¢** ×××•×¦×¢×™× ×•-percentiles
2. **×”×©×•×•××” ×‘×™×Ÿ ××©×›×•×œ×•×ª** ×©×•× ×™×
3. **× ×™×ª×•×— ×œ×¤×™ ×¡×•×’ ×¤×¢×•×œ×”**
4. **××’××•×ª ×‘×™×¦×•×¢×™×** ×œ××•×¨×š ×–××Ÿ

### × ×™×ª×•×— ×¤×¢×™×œ×•×ª ××©×ª××©×™×

```python
user_analysis = analytics.analyze_user_activity(days=7)

print(f"××©×ª××©×™× ×¤×¢×™×œ×™×: {user_analysis['unique_users']}")
print(f"×¤×¢×•×œ×•×ª: {user_analysis['total_user_actions']}")
```

---

## ğŸ’¾ ××¢×¨×›×ª ×™×™×¦×•× ×•×’×™×‘×•×™

### ×™×™×¦×•× ×œ×•×’×™×

```python
from core.log_export import LogExporter

exporter = LogExporter()

# ×™×™×¦×•× JSON ×¢× ×“×—×™×¡×”
json_file = exporter.export_logs_json(
    start_date=datetime.now() - timedelta(days=7),
    compress=True
)

# ×™×™×¦×•× Excel ×¢× ××¡×¤×¨ sheets
xlsx_file = exporter.export_logs_xlsx(
    start_date=datetime.now() - timedelta(days=1)
)
```

### ×¤×•×¨××˜×™ ×™×™×¦×•× × ×ª××›×™×

1. **CSV** - ×¢× ××¤×©×¨×•×ª ×“×—×™×¡×” GZIP
2. **JSON** - ×¢× metadata ××œ×
3. **Excel** - ×¢× ××¡×¤×¨ sheets ×•×¡×™×›×•××™×

### ×’×™×‘×•×™×™× ××•×˜×•××˜×™×™×

```python
# ×’×™×‘×•×™ ××œ× ×©×œ ×”××¢×¨×›×ª
full_backup = exporter.create_backup("full")

# ×’×™×‘×•×™ × ×ª×•× ×™× ××”×©×‘×•Ø¹ ×”××—×¨×•×Ÿ
recent_backup = exporter.create_backup("recent")

# ×’×™×‘×•×™ ×‘×¡×™×¡ ×”× ×ª×•× ×™× ×‘×œ×‘×“
db_backup = exporter.create_backup("database_only")
```

### × ×™×”×•×œ ×’×™×‘×•×™×™×

- **×“×—×™×¡×” ××•×˜×•××˜×™×ª** ×œ-ZIP
- **metadata** ××œ× ×¢×œ ×”×’×™×‘×•×™
- **×©×—×–×•×¨** ××’×™×‘×•×™ ×§×™×™×
- **× ×™×§×•×™ ×’×™×‘×•×™×™× ×™×©× ×™×**

---

## âš™ï¸ ×”×’×“×¨×•×ª ×•×”×ª×××” ××™×©×™×ª

### ×§×•× ×¤×™×’×•×¨×¦×™×” ×‘×¡×™×¡×™×ª

```python
config = {
    "log_dir": "logs",              # ×ª×™×§×™×™×ª ×œ×•×’×™×
    "log_level": "INFO",            # ×¨××ª ×œ×•×’ ××™× ×™××œ×™×ª
    "max_file_size": 50 * 1024 * 1024,  # 50MB
    "backup_count": 10,             # ××¡×¤×¨ ×§×‘×¦×™ backup
    "database_enabled": True,       # ×©××™×¨×” ×‘×‘×¡×™×¡ × ×ª×•× ×™×
    "console_enabled": True,        # ×”×¦×’×” ×‘×§×•× ×¡×•×œ
    "json_enabled": True,           # ×§×•×‘×¥ JSON
    "slack_webhook": None,          # URL ×œ-Slack
    "retention_days": 30,           # ×™××™× ×œ×©××™×¨×”
}

logger_system = RedshiftManagerLogger(config)
```

### ×”×ª×¨××•×ª Slack
```python
config["slack_webhook"] = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
```

×©×’×™××•×ª ×‘×¨××ª ERROR ×•CRITICAL ×™×™×©×œ×—×• ××•×˜×•××˜×™×ª ×œ-Slack.

---

## ğŸ› ï¸ ×¤×•× ×§×¦×™×•×ª ×¢×–×¨

### ×©×œ×™×¤×ª ×œ×•×’×™× ×¤×¨×•×’×¨××˜×™×ª

```python
from core.logging_system import logger_system

# ×©×œ×™×¤×ª ×œ×•×’×™× ×¢× ×¡×™× ×•×Ÿ
df = logger_system.get_logs(
    start_date=datetime.now() - timedelta(hours=1),
    level="ERROR",
    user_id="admin",
    limit=100
)

# ×¡×˜×˜×™×¡×˜×™×§×•×ª ××¢×¨×›×ª
stats = logger_system.get_log_statistics()
```

### × ×™×§×•×™ ×œ×•×’×™× ×™×©× ×™×

```python
# × ×™×§×•×™ ××•×˜×•××˜×™ ×œ×¤×™ ××“×™× ×™×•×ª retention
logger_system.cleanup_old_logs()

# × ×™×§×•×™ ×™×™×¦×•××™× ×™×©× ×™×
from core.log_export import LogExporter
exporter = LogExporter()
cleaned_count = exporter.cleanup_old_exports(days_to_keep=30)
```

---

## ğŸ“± ××™× ×˜×’×¨×¦×™×” ×¢× ×”××¢×¨×›×ª ×”×§×™×™××ª

×”××¢×¨×›×ª ××©×•×œ×‘×ª ×‘××•×¤×Ÿ ××œ× ×¢× RedshiftManager:

### ×‘×“×©×‘×•×¨×“ ×”×¨××©×™
```python
from core.logging_system import log_user_action, get_logger

logger = get_logger("dashboard")

def show_dashboard_page():
    log_user_action("page_view", "system", page="dashboard")
    logger.info("Dashboard page accessed")
    # ... ×§×•×“ ×”×“×©×‘×•×¨×“
```

### ×‘×‘×™×¦×•×¢ ×©××™×œ×ª×•×ª
```python
from core.logging_system import log_query

def execute_query(query, cluster_id, user_id):
    start_time = time.time()
    try:
        # ×‘×™×¦×•×¢ ×”×©××™×œ×ª×”
        result = run_query(query)
        
        # ×œ×•×’ ×”×¦×œ×—×”
        log_query(
            query=query,
            cluster_id=cluster_id,
            user_id=user_id,
            duration=(time.time() - start_time) * 1000,
            rows_affected=len(result),
            status="SUCCESS"
        )
        
    except Exception as e:
        # ×œ×•×’ ×©×’×™××”
        logger.error(f"Query failed: {e}", extra={
            "query": query,
            "cluster_id": cluster_id,
            "user_id": user_id
        })
```

---

## ğŸ”§ ×‘×¢×™×•×ª × ×¤×•×¦×•×ª ×•×¤×ª×¨×•× ×•×ª

### ×”××¢×¨×›×ª ×œ× ×›×•×ª×‘×ª ×œ×•×’×™×
- ×‘×“×•×§ ×©×ª×™×§×™×™×ª `logs/` × ×•×¦×¨×”
- ×‘×“×•×§ ×”×¨×©××•×ª ×›×ª×™×‘×”
- ×•×“× ×©×”××•×“×•×œ ××™×•×‘× × ×›×•×Ÿ

### ×‘×¡×™×¡ ×”× ×ª×•× ×™× × ×¢×•×œ
```python
# ×”×•×¡×£ timeout ×œ×—×™×‘×•×¨
conn = sqlite3.connect(self.db_path, timeout=30)
```

### ×§×‘×¦×™ ×œ×•×’ ×’×“×•×œ×™× ××“×™
- ×”×’×“×¨ `max_file_size` × ××•×š ×™×•×ª×¨
- ×”×’×‘×¨ ××ª `backup_count`
- ×”×©×ª××© ×‘×“×—×™×¡×”

### ×‘×™×¦×•×¢×™× ××™×˜×™×™×
- ×”×’×“×œ ××ª `batch_size` ×‘×›×ª×™×‘×” ×œ×‘×¡×™×¡ × ×ª×•× ×™×
- ×”×©×ª××© ×‘××™× ×“×§×¡×™× × ×•×¡×¤×™×
- ×”×¤×¢×œ × ×™×§×•×™ ×œ×•×’×™× ×™×©× ×™×

---

## ğŸ“Š ××“×“×™ ×‘×™×¦×•×¢×™×

×”××¢×¨×›×ª ××•×ª×××ª ×œ×˜×™×¤×•×œ ×‘:
- **100,000+ ×œ×•×’×™× ×‘×™×•×**
- **×—×™×¤×•×©×™× ××”×™×¨×™×** ×¢× ××™× ×“×§×¡×™×
- **×™×™×¦×•× ×’×“×•×œ** ×¢×“ 1GB+
- **×’×™×‘×•×™×™× ××”×™×¨×™×** ×¢× ×“×—×™×¡×”

---

## ğŸ¯ ×”××œ×¦×•×ª ×œ×©×™××•×©

### ×œ×¤×™×ª×•×—
- ×”×©×ª××© ×‘×¨××ª DEBUG ×œ×¤×¨×˜×™× ××œ××™×
- ×”×•×¡×£ context ××œ× ×¢× `extra` fields
- ×‘×“×•×§ ×œ×•×’×™× ×œ××—×¨ ×›×œ ×©×™× ×•×™

### ×œ×™×™×¦×•×¨
- ×”×©×ª××© ×‘×¨××ª INFO ××• WARNING
- ×”×¤×¢×œ × ×™×§×•×™ ××•×˜×•××˜×™
- ×”×’×“×¨ ×”×ª×¨××•×ª Slack
- ×¦×•×¨ ×’×™×‘×•×™×™× ×ª×§×•×¤×ª×™×™×

### ×œ××¢×§×‘ ×•×ª×—×–×•×§×”
- ×¢×§×•×‘ ××—×¨ ××’××•×ª ×©×’×™××•×ª
- × ×ª×— ×‘×™×¦×•×¢×™× ×©×‘×•×¢×™×ª
- ×‘×“×•×§ ×“×¤×•×¡×™ ×©×™××•×© ××©×ª××©×™×
- ×™×¦× ×“×•×—×•×ª ×œ× ×™×ª×•×— ×—×™×¦×•× ×™

---

## ğŸ”® ×ª×•×›× ×™×•×ª ×¢×ª×™×“×™×•×ª

- **ElasticSearch integration** ×œ×—×™×¤×•×© ××ª×§×“×
- **Grafana dashboards** ×œ×•×•×™×–×•××œ×™×–×¦×™×”
- **Machine Learning** ×œ×–×™×”×•×™ ×× ×•××œ×™×•×ª
- **Real-time alerts** ×¢× Webhook
- **API endpoints** ×œ×’×™×©×” ×—×™×¦×•× ×™×ª

---

*××¢×¨×›×ª ×”×œ×•×’×™× × ×•×¦×¨×” ×›×—×œ×§ ×-RedshiftManager ×•××¡×¤×§×ª ×¤×ª×¨×•×Ÿ ××§×™×£ ×œ× ×™×˜×•×¨, × ×™×ª×•×— ×•× ×™×”×•×œ ×œ×•×’×™×.*